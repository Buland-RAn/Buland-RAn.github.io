<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>AYu</title>
  <meta name="author" content="AYu">
  
  <meta name="description" content="学习生活片段记录">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="AYu"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.ico" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-70812759-1', 'auto');
  ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?cb5448498d7169c668b07c2b255d62c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


<meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="atom.xml" title="AYu" type="application/atom+xml">
</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">AYu</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archive" title="All the articles.">
			  <i class=""></i>Archive
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		  <li>
			<a href="/atom.xml" title="Subscribe me.">
			  <i class=""></i>RSS
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> </h1>
		</div>
	


<script src='//unpkg.com/valine/dist/Valine.min.js'></script>

<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <p>.<a id="more"></a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_25420115/article/details/52822584">向数据中添加高斯噪声</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29360425">深入理解L1、L2正则化</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/45054166">PRML Chapter 1 (section 1)</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/98642663">共轭梯度法（一）：线性共轭梯度</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32488420">理解机器学习中的 L2 正则化</a></li>
<li><a target="_blank" rel="noopener" href="https://cxybb.com/article/qq_40349484/112697129">训练参数为nan_学习率问题</a></li>
<li><a target="_blank" rel="noopener" href="https://cosx.org/2016/11/conjugate-gradient-for-regression/">共轭梯度法计算回归</a></li>
</ol>
<h2 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h2><p>掌握最小二乘法求解（无惩罚项的损失函数）、掌握加惩罚项（2范数）的损失函数优化、梯度下降法、共轭梯度法、理解过拟合、克服过拟合的方法(如加惩罚项、增加样本)。</p>
<h2 id="二、实验要求及实验环境"><a href="#二、实验要求及实验环境" class="headerlink" title="二、实验要求及实验环境"></a>二、实验要求及实验环境</h2><p><strong>要求：</strong></p>
<ol>
<li><p>生成数据，加入噪声；</p>
</li>
<li><p>用高阶多项式函数拟合曲线；</p>
</li>
<li><p>用解析解求解两种loss的最优解（无正则项和有正则项）</p>
</li>
<li><p>优化方法求解最优解（梯度下降，共轭梯度）；</p>
</li>
<li><p>用你得到的实验数据，解释过拟合。</p>
</li>
<li><p>用不同数据量，不同超参数，不同的多项式阶数，比较实验效果。</p>
</li>
</ol>
<p><strong>实验环境：</strong></p>
<p>Google colab：python</p>
<h2 id="三、设计思想（本程序中的用到的主要算法及数据结构）"><a href="#三、设计思想（本程序中的用到的主要算法及数据结构）" class="headerlink" title="三、设计思想（本程序中的用到的主要算法及数据结构）"></a>三、设计思想（本程序中的用到的主要算法及数据结构）</h2><p><strong>数据结构：</strong>数组/向量/矩阵</p>
<p><strong>算法：</strong></p>
<ol>
<li>解析法求最优解</li>
</ol>
<p>无正则项时，通过对目标函数</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image002.jpg" alt="img"></p>
<p>求导可以得到</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image004.jpg" alt="img"></p>
<p>加入正则项，则目标函数变为</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image006.jpg" alt="img"></p>
<p>解为</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image008.jpg" alt="img"></p>
<ol start="2">
<li>梯度下降法</li>
</ol>
<p>1）确定当前位置的损失函数的梯度，对于θi,其梯度表达式如下：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image010.jpg" alt="img"></p>
<p>2）用步长乘以损失函数的梯度，得到当前位置下降的距离，即：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image012.jpg" alt="img"></p>
<p>3）确定是否所有的θi，梯度下降的距离都小于ε，如果小于ε则算法终止（或者指定迭代次数），当前所有的θi(i=0,1,…n)即为最终结果。否则进入步骤4.</p>
<p>4）更新所有的θ，对于θi，其更新表达式如下。更新完毕后继续转入步骤1.</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image014.jpg" alt="img"></p>
<p>矩阵表达方式：<img src="/2021/Polynomial-machine-learning/clip_image016.jpg" alt="img"></p>
<ol start="3">
<li>共轭梯度法</li>
</ol>
<p>在回归模型中，回归系数β正是线性方程组 Ax=b 的解，其中 A=X′X，b=X′y。共轭梯度法，就是想像上面这个式子一样，把解x表达成共轭向量基的线性组合：只要依次算出所有的共轭向量pi和对应的系数αi，就可以得出x。而在实际情况中，有可能用更少数目的pi就能得到对x的良好近似。</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image018.jpg" alt="img"></p>
<h2 id="四、实验结果与分析"><a href="#四、实验结果与分析" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><p>当数据量小（=10）时：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image020.jpg" alt="img"></p>
<p>不带正则项的解析解得出的参数预测结果在M=9时出现了严重的过拟合现象：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image022.jpg" alt="img"></p>
<p>随着M的增大，在训练集上的误差越来越小，但在测试集上的误差在M&gt;6后开始增大：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image024.jpg" alt="img"></p>
<p>当加上正则项后，M=9时也没有出现过拟合现象：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image026.jpg" alt="img"></p>
<p>超参数λ的选择会影响正则化的效果，当λ太小和接近1时训练集的误差都很大，在训练集上的误差由于控制了参数的大小也随着增大：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image028.jpg" alt="img"></p>
<p>使用梯度下降法，学习率取太大会使M=9的模型参数变得太大而无法计算，而太小会影响计算速度，最终取α= 0.01，迭代次数为1000000，结果如下：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image030.jpg" alt="img"></p>
<p>使用共轭梯度法时，设定误差阈值为1e-10，在M=9时也会出现过拟合现象：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image032.jpg" alt="img"></p>
<p>当数据量由10增加至30时，过拟合现象明显减缓.</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image034.jpg" alt="img"></p>
<p>解析解不带正则项方法：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image036.jpg" alt="img"></p>
<p>对应Erms图：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image038.jpg" alt="img"></p>
<p>在测试集上的误差明显减小。</p>
<p>在解析解带正则项方法中表现也有所改进：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image040.jpg" alt="img"></p>
<p><img src="/2021/Polynomial-machine-learning/clip_image042.jpg" alt="img"></p>
<p>共轭梯度法M=9的模型过拟合现象也减轻了：</p>
<p><img src="/2021/Polynomial-machine-learning/clip_image044.jpg" alt="img"></p>
<h2 id="五、结论"><a href="#五、结论" class="headerlink" title="五、结论"></a>五、结论</h2><ol>
<li><p>解析解方法能够得到回归的精确解，在特征量合适时可以使用。</p>
</li>
<li><p>梯度下降法能够通过控制迭代次数控制解的优化程度，适合于不太需要精确解的场合。</p>
</li>
<li><p>共轭梯度法既可以求出精确解，也可以在中途停下，同时因为减少了曲折的迭代路线比梯度下降法效率更高，是较优的选择。</p>
</li>
<li><p>当出现过拟合现象时，原因可能是数据量不够或者模型设定得过于复杂，可以通过增加正则项、增大数据量或者减少模型复杂度解决。</p>
</li>
</ol>
<h2 id="六、源代码（带注释）"><a href="#六、源代码（带注释）" class="headerlink" title="六、源代码（带注释）"></a>六、源代码（带注释）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data_1</span>(<span class="params">size</span>):</span>  <span class="comment">#随机生成数据点</span></span><br><span class="line">  x = np.random.rand(size)</span><br><span class="line">  y = np.sin(<span class="number">2</span> * np.pi * x) + np.random.normal(<span class="number">0</span>,<span class="number">0.3</span>,size)</span><br><span class="line">  <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data_2</span>(<span class="params">size</span>):</span>  <span class="comment">#等距生成数据点</span></span><br><span class="line">  x = np.linspace(<span class="number">0</span>,<span class="number">1</span>,size)</span><br><span class="line">  y = np.sin(<span class="number">2</span> * np.pi * x) + np.random.normal(<span class="number">0</span>,<span class="number">0.3</span>,size)</span><br><span class="line">  <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line">size = <span class="number">30</span></span><br><span class="line">x_train, y_train = generate_data_2(size)</span><br><span class="line">x_func = np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">y_func = np.sin(<span class="number">2</span> * np.pi * x_func)</span><br><span class="line">plt.plot(x_train,y_train,<span class="string">&#x27;.b&#x27;</span>)</span><br><span class="line">plt.plot(x_func,y_func,<span class="string">&#x27;-g&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">polynomial_X</span>(<span class="params">x, exp</span>):</span>   <span class="comment">#构造输入特征矩阵</span></span><br><span class="line">  <span class="keyword">if</span>(exp == <span class="number">0</span>):</span><br><span class="line">    <span class="keyword">return</span> np.ones(x.size)</span><br><span class="line">  X = np.vstack((np.ones(x.size),x))   <span class="comment">#将X的第一列设为全1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, exp+<span class="number">1</span>):</span><br><span class="line">    X = np.vstack((X, np.power(x, i)))</span><br><span class="line">  <span class="keyword">return</span> X.T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_analytic</span>(<span class="params">x_train, exp</span>):</span>  <span class="comment">#不带正则项解析法求参</span></span><br><span class="line">  X = polynomial_X(x_train, exp)</span><br><span class="line">  <span class="keyword">if</span>(exp == <span class="number">0</span>):      <span class="comment"># M=0的情况特殊处理，不能使用pinv函数</span></span><br><span class="line">    theta = <span class="number">1</span>/(X.T.dot(X)) * X.T.dot(y_train)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    theta = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y_train)</span><br><span class="line">  <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_analytic</span>(<span class="params">x_train, x_test, exp</span>):</span>  <span class="comment">#不带正则项解析法预测</span></span><br><span class="line">  theta = train_analytic(x_train, exp)</span><br><span class="line">  <span class="keyword">return</span> polynomial_X(x_test, exp).dot(theta)</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">9</span>]:</span><br><span class="line">  y_predict = predict_analytic(x_train, x_func, i)</span><br><span class="line">  plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">  j += <span class="number">1</span></span><br><span class="line">  plt.plot(x_func, y_predict, <span class="string">&#x27;-r&#x27;</span>)</span><br><span class="line">  plt.plot(x_train,y_train,<span class="string">&#x27;.b&#x27;</span>)</span><br><span class="line">  plt.plot(x_func,y_func,<span class="string">&#x27;-g&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_erms</span>(<span class="params">y, t</span>):</span>   <span class="comment">#计算Erms</span></span><br><span class="line">  <span class="keyword">return</span> np.sqrt(np.mean(np.square(y-t)))</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])  <span class="comment">#Erms图的x轴，代表degree</span></span><br><span class="line">training_erms = np.zeros(<span class="number">10</span>)</span><br><span class="line">test_erms = np.zeros(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">theta = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">  theta.append(train_analytic(x_train, i))</span><br><span class="line">  y_train_predict = polynomial_X(x_train, i).dot(theta[i])</span><br><span class="line">  training_erms[i] = calculate_erms(y_train_predict, y_train)</span><br><span class="line">  y_test_predict = predict_analytic(x_train, x_func, i)</span><br><span class="line">  test_erms[i] = calculate_erms(y_test_predict, </span><br><span class="line">y_func+np.random.normal(<span class="number">0</span>,<span class="number">0.3</span>,len(y_func)))  <span class="comment">#真实数据有高斯分布的误差</span></span><br><span class="line"></span><br><span class="line">plt.plot(x, training_erms, <span class="string">&#x27;o-b&#x27;</span>, label=<span class="string">&quot;Training&quot;</span>)</span><br><span class="line">plt.plot(x, test_erms, <span class="string">&#x27;o-r&#x27;</span>, label=<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;degree&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Erms&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_analytic_with_regularization</span>(<span class="params">x_train, exp, lamb</span>):</span>   <span class="comment">#带正则项解析法求参</span></span><br><span class="line">  X = polynomial_X(x_train, exp)</span><br><span class="line">  <span class="keyword">if</span>(exp == <span class="number">0</span>):</span><br><span class="line">    theta = <span class="number">1</span>/(X.T.dot(X)+lamb) * X.T.dot(y_train)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    theta = np.linalg.pinv(X.T.dot(X)+lamb*np.eye(X.shape[<span class="number">1</span>])).dot(X.T).dot(y_train)</span><br><span class="line">  <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_analytic_with_regularization</span>(<span class="params">x_train, x_test, exp, lamb</span>):</span>  <span class="comment">#带正则项解析法预测</span></span><br><span class="line">  theta = train_analytic_with_regularization(x_train, exp, lamb)</span><br><span class="line">  <span class="keyword">return</span> polynomial_X(x_test, exp).dot(theta)</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line">lamb = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">9</span>]:</span><br><span class="line">  y_predict = predict_analytic_with_regularization(x_train,x_func,i,lamb)</span><br><span class="line">  plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">  j += <span class="number">1</span></span><br><span class="line">  plt.plot(x_func,y_predict, <span class="string">&#x27;-r&#x27;</span>)</span><br><span class="line">  plt.plot(x_train,y_train,<span class="string">&#x27;.b&#x27;</span>)</span><br><span class="line">  plt.plot(x_func,y_func,<span class="string">&#x27;-g&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-40</span>, <span class="number">0</span>)   <span class="comment">#Erms图x轴，代表lnλ的值</span></span><br><span class="line">training_erms = np.zeros_like(x)</span><br><span class="line">test_erms = np.zeros_like(x)</span><br><span class="line"></span><br><span class="line">X = polynomial_X(x_train, <span class="number">9</span>)  <span class="comment">#选择M=9观察正则项效果</span></span><br><span class="line">theta = []</span><br><span class="line"><span class="keyword">for</span> i,index <span class="keyword">in</span> zip(x, range(x.size)):</span><br><span class="line">  theta.append(train_analytic_with_regularization(x_train, <span class="number">9</span>, np.exp(i)))</span><br><span class="line">  y_train_predict = X.dot(theta[index])</span><br><span class="line">  training_erms[index] = calculate_erms(y_train_predict, y_train)</span><br><span class="line">  y_test_predict = predict_analytic_with_regularization(x_train, x_func, <span class="number">9</span>, np.exp(i))</span><br><span class="line">  test_erms[index] = calculate_erms(y_test_predict, </span><br><span class="line">y_func+np.random.normal(<span class="number">0</span>,<span class="number">0.3</span>,len(y_func)))</span><br><span class="line"></span><br><span class="line">plt.plot(x, training_erms, <span class="string">&#x27;o-b&#x27;</span>, label=<span class="string">&quot;Training&quot;</span>)</span><br><span class="line">plt.plot(x, test_erms, <span class="string">&#x27;o-r&#x27;</span>, label=<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;lnλ&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Erms&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span>(<span class="params">X, y, alpha, iterations</span>):</span>  <span class="comment">#梯度下降法求参</span></span><br><span class="line">  <span class="keyword">if</span>(np.size(X.shape) == <span class="number">1</span>):  <span class="comment">#若X只有一列，代表只有一个参数</span></span><br><span class="line">    theta = <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    theta = np.zeros(np.size(X, <span class="number">1</span>))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">    theta = theta - alpha * X.T.dot(X.dot(theta) - y)</span><br><span class="line">  <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent_predict</span>(<span class="params">X, y_train, X_test, exp, alpha, iterations</span>):</span></span><br><span class="line">  theta = gradient_descent(X, y_train, alpha, iterations)</span><br><span class="line">  <span class="keyword">if</span>(exp == <span class="number">9</span>):</span><br><span class="line">    print(<span class="string">&quot;M=9时，theta=&quot;</span>, theta)  <span class="comment"># 查看M=9时得到的theta值</span></span><br><span class="line">  <span class="keyword">return</span> X_test.dot(theta)</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line">iterations = <span class="number">1000000</span></span><br><span class="line"><span class="comment"># X = polynomial_X(x_train, 5)</span></span><br><span class="line"><span class="comment"># X_test = polynomial_X(x_func, 5)</span></span><br><span class="line"><span class="comment"># for alpha in [0.01, 0.03, 0.1, 0.3]:</span></span><br><span class="line"><span class="comment">#   plt.subplot(2,2,j)</span></span><br><span class="line"><span class="comment">#   j += 1</span></span><br><span class="line"><span class="comment">#   y_predict = gradient_descent_predict(X, y_train, X_test, 5, alpha, iterations)</span></span><br><span class="line"><span class="comment">#   plt.plot(x_func,y_predict,&#x27;-r&#x27;)</span></span><br><span class="line"><span class="comment">#   plt.plot(x_train,y_train,&#x27;.b&#x27;)</span></span><br><span class="line"><span class="comment">#   plt.plot(x_func,y_func,&#x27;-g&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">9</span>]:</span><br><span class="line">  plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">  j += <span class="number">1</span></span><br><span class="line">  X = polynomial_X(x_train, i)</span><br><span class="line">  X_test = polynomial_X(x_func, i)</span><br><span class="line">  y_predict = gradient_descent_predict(X, y_train, X_test, i, <span class="number">0.01</span>, iterations)</span><br><span class="line">  plt.plot(x_func,y_predict,<span class="string">&#x27;-r&#x27;</span>)</span><br><span class="line">  plt.plot(x_train,y_train,<span class="string">&#x27;.b&#x27;</span>)</span><br><span class="line">  plt.plot(x_func,y_func,<span class="string">&#x27;-g&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># X = polynomial_X(x_train, 9)</span></span><br><span class="line"><span class="comment"># X_test = polynomial_X(x_func, 9)</span></span><br><span class="line"><span class="comment"># y_predict = gradient_descent_predict(X, y_train, X_test, 9, 0.0001, 1000000000)</span></span><br><span class="line"><span class="comment"># plt.plot(x_func,y_predict,&#x27;-r&#x27;)</span></span><br><span class="line"><span class="comment"># plt.plot(x_train,y_train,&#x27;.b&#x27;)</span></span><br><span class="line"><span class="comment"># plt.plot(x_func,y_func,&#x27;-g&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conjugate_gradient</span>(<span class="params">X, y</span>):</span>   <span class="comment">#共轭梯度法求参</span></span><br><span class="line">  esp = <span class="number">1e-10</span>          <span class="comment">#当误差小于该值时停止迭代</span></span><br><span class="line">  A = X.T.dot(X)</span><br><span class="line">  b = X.T.dot(y)</span><br><span class="line">  <span class="keyword">if</span> (np.size(X.shape) == <span class="number">1</span>):</span><br><span class="line">    theta = <span class="number">0</span></span><br><span class="line">    r = b - A*theta</span><br><span class="line">    p = r</span><br><span class="line">    r2 = r*r</span><br><span class="line">    alpha = r2 / (p * A * p)</span><br><span class="line">    theta = theta + alpha * p</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    theta = np.zeros(np.size(X, <span class="number">1</span>))</span><br><span class="line">    r = b - A.dot(theta)</span><br><span class="line">    p = r</span><br><span class="line">    r2 = r.T.dot(r)</span><br><span class="line">    err = <span class="number">1</span></span><br><span class="line">    <span class="comment"># for i in range(np.size(X, 1)):</span></span><br><span class="line">    <span class="keyword">while</span> err &gt; esp:</span><br><span class="line">      alpha = r2 / (p.T.dot(A).dot(p))</span><br><span class="line">      theta = theta + alpha * p</span><br><span class="line">      r = r - alpha * A.dot(p)</span><br><span class="line">      r2_new = r.T.dot(r)</span><br><span class="line">      err = np.sqrt(r2_new)</span><br><span class="line">      beta = r2_new / r2</span><br><span class="line">      p = r + beta * p</span><br><span class="line">      r2 = r2_new</span><br><span class="line">  <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conjugate_gradient_predict</span>(<span class="params">X_train, y_train, X_test</span>):</span></span><br><span class="line">  theta = conjugate_gradient(X_train, y_train)</span><br><span class="line">  <span class="comment"># if(exp == 9):</span></span><br><span class="line">  <span class="comment">#   print(&quot;M=9时，theta=&quot;, theta)  # 查看M=9时得到的theta值</span></span><br><span class="line">  <span class="keyword">return</span> X_test.dot(theta)</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">9</span>]:</span><br><span class="line">  plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">  j += <span class="number">1</span></span><br><span class="line">  y_predict = conjugate_gradient_predict(polynomial_X(x_train, i), </span><br><span class="line">y_train, polynomial_X(x_func, i))</span><br><span class="line">  plt.plot(x_func,y_predict,<span class="string">&#x27;-r&#x27;</span>)</span><br><span class="line">  plt.plot(x_train,y_train,<span class="string">&#x27;.b&#x27;</span>)</span><br><span class="line">  plt.plot(x_func,y_func,<span class="string">&#x27;-g&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<h2 id="七、附ipynb文件"><a href="#七、附ipynb文件" class="headerlink" title="七、附ipynb文件"></a>七、附ipynb文件</h2>	  
	</div>

	<div>
  	<center>
	<div class="pagination">

    
    
    <a href="/2021/machine-learning-logistic-regression/" type="button" class="btn btn-default"><i
                class="fa fa-arrow-circle-o-left"></i> 上一页</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2021/null/" type="button" class="btn btn-default ">下一页<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>

    </center>
	</div>
	
	<!-- comment -->
	<!-- 
<section id="comment">
    <h2 class="title">留言</h2>

    
</section>
 -->


    <section id="comment">
        <h2 class="title">
            留言
        </h2>
        <div id="vcomments"></div>
        <script>
            new Valine({
                el: '#vcomments',
                appId: '8FWjWdEoyYxwoFgc2ET6DcSh-gzGzoHsz',
                appKey: 'DqH3LDGq73YqdepEDCcPgWhl',
                visitor: true,
                // avatar: 'hide',
                avatar: 'retro',
                // 这里设置CDN, 默认微博表情CDN
                // emojiCDN: 'https://img.t.sinajs.cn/t4/appstyle/expression/ext/normal/',
                // // 表情title和图片映射
                // emojiMaps: {
                //     "smile": "e3/2018new_weixioa02_org.png",
                //     "lovely": "09/2018new_keai_org.png",
                //     // ... 更多表情
                // }
            })
        </script>
    </section>


    <style type="text/css">
        h2.title {
            font-size: 25px;
            margin-bottom: 27px;
        }

        .v[data-class=v] .vwrap {
            border: 3px solid #f0f0f0;
        }
    
        .v[data-class=v] .vwrap .vheader .vinput {
            border-bottom: 1.8px dashed #f5f5f5;
            color: #bebaba;
            font-size: 17px;
        }

        .v[data-class=v] .veditor {
            font-size: 1.2em;
            color: #b5b5b5;
        }

        .v[data-class=v] .vrow .vcol {
            
            font-size: 17px;
        }

        .v[data-class=v] .vicon {
            fill: #bebebe;
        }

        .v[data-class=v] .vrow {
            font-size: 0;
            padding: 10px 0 0;
        }

        .v[data-class=v] .vbtn {
            color: #d0cdcd;
        }
        
        .v[data-class=v] .vsys {
            padding: 0em 0em;
        }

        .v[data-class=v] .vcards .vcard {
            padding-top: 0em;
        }

        .v[data-class=v] p {
            margin-bottom: 0;
            color: #c0c0c0;
        }

        a:hover {
            font-weight: 800 !important;
        }

        .v[data-class=v] a:hover{
            color: #c66400;
            background: bottom !important;
        }

        .v[data-class=v] a.vnick:hover{
            color: #c66400 !important;
            background: bottom !important;
        }

        .v[data-class=v] .vwrap .vheader .vinput:focus {
            border-bottom-color: #ff7c29;
        }

    </style>





	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2021-09-27 
	</div>
	
	<span id="busuanzi_container_page_pv">
		<i class="fa fa-eye"></i>
  		<span id="busuanzi_value_page_pv"></span>
    </span>

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/机器学习/">机器学习<span>3</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/实验/">实验<span>4</span></a></li>
  
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
		   <span class="toc-title">Contents</span>
			<ol class="toc-article"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E5%8F%82%E8%80%83"><span class="toc-article-text">参考</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-article-text">一、实验目的</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E9%AA%8C%E8%A6%81%E6%B1%82%E5%8F%8A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-article-text">二、实验要求及实验环境</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%B8%89%E3%80%81%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E6%9C%AC%E7%A8%8B%E5%BA%8F%E4%B8%AD%E7%9A%84%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%BB%E8%A6%81%E7%AE%97%E6%B3%95%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%89"><span class="toc-article-text">三、设计思想（本程序中的用到的主要算法及数据结构）</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%88%86%E6%9E%90"><span class="toc-article-text">四、实验结果与分析</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%BA%94%E3%80%81%E7%BB%93%E8%AE%BA"><span class="toc-article-text">五、结论</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E5%85%AD%E3%80%81%E6%BA%90%E4%BB%A3%E7%A0%81%EF%BC%88%E5%B8%A6%E6%B3%A8%E9%87%8A%EF%BC%89"><span class="toc-article-text">六、源代码（带注释）</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%B8%83%E3%80%81%E9%99%84ipynb%E6%96%87%E4%BB%B6"><span class="toc-article-text">七、附ipynb文件</span></a></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2022 AYu
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br>     
     <span id="busuanzi_container_site_pv">
    	👀: <span id="busuanzi_value_site_pv"></span>    |   🙋: <span id="busuanzi_value_site_uv"></span>
	</span>
</p>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
